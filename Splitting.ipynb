{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7464eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84fddfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBAS Muhammad</td>\n",
       "      <td>Alpine Skiing</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABLAEV Enver</td>\n",
       "      <td>Freestyle Skiing</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>30</td>\n",
       "      <td>68.0</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABRAMASHVILI Iason</td>\n",
       "      <td>Alpine Skiing</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>21</td>\n",
       "      <td>82.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABRAMENKO Evgeny</td>\n",
       "      <td>Biathlon</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>22</td>\n",
       "      <td>81.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABRAMENKO Oleksandr</td>\n",
       "      <td>Freestyle Skiing</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>21</td>\n",
       "      <td>74.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name             Sport Nationality  Age  Weight  Height\n",
       "0       ABBAS Muhammad     Alpine Skiing    Pakistan   23    55.0   168.0\n",
       "2         ABLAEV Enver  Freestyle Skiing     Ukraine   30    68.0   169.0\n",
       "3   ABRAMASHVILI Iason     Alpine Skiing     Georgia   21    82.0   176.0\n",
       "4     ABRAMENKO Evgeny          Biathlon     Belarus   22    81.0   180.0\n",
       "5  ABRAMENKO Oleksandr  Freestyle Skiing     Ukraine   21    74.0   179.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Name','Sport','Nationality','Age','Weight','Height']\n",
    "df = pd.read_excel('sampledatawinterathletes.xlsx',names = columns)\n",
    "df.dropna(inplace=True,axis=0) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cfab81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Weight','Height']],df['Age'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2911a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aa22c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df34418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.075\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d77d78",
   "metadata": {},
   "source": [
    "Dataset splitting is a practice considered indispensable and highly necessary to eliminate or reduce bias to training data in Machine Learning Models. This process is always done by data scientists and data analysts to prevent the machine learning algorithms from resulted into an overfitting type which could perform poorly on the actual test data.\n",
    "\n",
    "The data should ideally be divided into 3 sets – namely, train, test, and holdout cross-validation or development (dev) set. Let’s first understand in brief what these sets mean and what type of data they should have. \n",
    "Train Set: \n",
    "The train set would contain the data which will be fed into the model. In simple terms, our model would learn from this data. For instance, a Regression model would use the examples in this data to find gradients in order to reduce the cost function. Then these gradients will be used to reduce the cost and predict data effectively.\n",
    "Dev Set: \n",
    "The development set is used to validate the trained model. This is the most important setting as it will form the basis of our model evaluation. If the difference between error on the training set and error on the dev set is huge, it means the model as high variance and hence, a case of over-fitting.\n",
    "Test Set: \n",
    "The test set contains the data on which we test the trained and validated model. It tells us how efficient our overall model is and how likely is it going to predict something which does not make sense. There are a plethora of evaluation metrics (like precision, recall, accuracy, etc.) which can be used to measure the performance of our model.\n",
    "\n",
    "Scikit-learn alias sklearn is the most useful and robust library for machine learning in Python. The scikit-learn library provides us with the model_selection module in which we have the splitter function train_test_split().\n",
    "\n",
    "syntax:\n",
    "train_test_split(*arrays, test_size=None, train_size=None, random_state=None)\n",
    "Parameters:\n",
    "\n",
    "*arrays: inputs such as lists, arrays, data frames, or matrices\n",
    "test_size: this is a float value whose value ranges between 0.0 and 1.0. it represents the proportion of our test size. its default value is none.\n",
    "train_size: this is a float value whose value ranges between 0.0 and 1.0. it represents the proportion of our train size. its default value is none.\n",
    "random_state: this parameter is used to control the shuffling applied to the data before applying the split. it acts as a seed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
