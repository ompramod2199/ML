{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7464eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84fddfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Ompramod9921/Iris_classificaton/main/Iris.csv')\n",
    "df.drop(\"Id\",inplace=True,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1cfab81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']],df['Species'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2911a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "mymodel = linear_model.LogisticRegression(max_iter=120)\n",
    "mymodel.fit(X_train,y_train)\n",
    "y_pred = mymodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "50bd822b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 0],\n",
       "       [0, 3, 1],\n",
       "       [0, 0, 7]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f194b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9aa22c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "10b650ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.933\n"
     ]
    }
   ],
   "source": [
    "print('Recall: %.3f' % recall_score(y_test, y_pred, \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df34418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.933\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c9ef6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.933\n"
     ]
    }
   ],
   "source": [
    "print('Precision: %.3f' % precision_score(y_test, y_pred, \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a28f8e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.933\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score: %.3f' % f1_score(y_test, y_pred, \n",
    "                                           pos_label='positive',\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4c0ce",
   "metadata": {},
   "source": [
    "Evaluating the performance of a Machine learning model is one of the important steps while building an effective ML model. To evaluate the performance or quality of the model, different metrics are used, and these metrics are known as performance metrics or evaluation metrics. These performance metrics help us understand how well our model has performed for the given data.\n",
    "\n",
    "Confusion Matrix:\n",
    "It Is A 2*2 Matrix That Shows Four Different Combinations Of Actual Value And Predicted Outcome. This Is Used For Binary Classification Problems.\n",
    "In general, the table is divided into four terminologies, which are as follows:\n",
    "True-Positive (TP): The Predicted Outcome Is Positive When Actually It Is Positive.\n",
    "False-Negative (FN): The Predicted Outcome Is Negative When It Is Actually Positive.\n",
    "True-Negative (TN): The Predicted Outcome Is Negative When Actually It Is Negative.\n",
    "False-Positive (FP): The Predicted Outcome Is Positive When Actually It Is Negative.\n",
    "\n",
    "Accuracy: \n",
    "It Is Defined As The Ratio Of Correct Predicted Values To The Total Number Of Predicted Values. Corrected Predicted Values Include Both Positive And Negative Values Which Are Predicted Correctly.\n",
    "\n",
    "Accuracy= Corrected Predicted Values/ Total Predicted Values\n",
    "\n",
    "From The Above Confusion Matrix,\n",
    "\n",
    "Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "The Value Of Accuracy Ranges From 0 To1. A Value Closer To 1 Indicates A Better Model.\n",
    "\n",
    "True Positive Rate Or TPR: The Ratio Of Actual Positive Predicted Values To The Total Actual Positive Values. The Range Varies From 0 To 1. The Higher The Value The Better Is The Model. This Is Also Called Sensitivity. \n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "\n",
    "False Negative Rate Or FNR: The Ratio Of Actual Positive, Predicted As Negative To Total Actual Positive Values. Lower The FNR Better Is The Model. This Is Also Called 1- Sensitivity \n",
    "\n",
    "FNR = FN/(TP+FN) \n",
    "\n",
    "True Negative Rate Or TNR: The Ratio Of Predicted Negative Values That Are Actually Negative To The Total Actual Negative Values.\n",
    "\n",
    "TNR= TN/ TN+FP\n",
    "\n",
    "It Is Also Refer Specificity. The Higher The Value The Better Is The Model.\n",
    "\n",
    "False Positive Rate Or FPR: The Ratio Of Actual Negative, Predicted As Positive To The Total Actual Negative Values.\n",
    "\n",
    "FPR =FP/ TN+FP\n",
    "\n",
    "It Is Known As 1- Specificity. Lower The Value Of FTR Better Is The Model.\n",
    "\n",
    "3. Recall:\n",
    "Out Of All Actual Positive Values, How Many Are Actually Predicted Positive.\n",
    "\n",
    "Recall =Predictions Positive/Total Actual Positive\n",
    "\n",
    "Recall = TP/TP+FN\n",
    "\n",
    "4. Precision: \n",
    "Out Of Total Positive Predicted Values How Many Are Actually Positive\n",
    "\n",
    "Precision= Predictions Actually Positive/ Total Predicted Positive\n",
    "\n",
    "Precision= TP/(TP+FP) \n",
    "\n",
    "Precision And Recall Are Select As Evaluation Matrix Depending On Business Scenario\n",
    "\n",
    "5. F1-Score: \n",
    "This Is A Combination Of Precision And Recall. It Can Be Define As The Harmonic Mean Of Precision And Recall. \n",
    "\n",
    "The Formula For F1-Score Is\n",
    "F1 Score = 2* [ (precision*recall) / (precision+recall)]\n",
    "The Value Ranges From 0 To 1. F1-Score Is Maximum When Precision = Recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
